{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional neural network core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random,csv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(feature_list,label_list,size):\n",
    "    feature_batch_temp=[]\n",
    "    label_batch_temp=[]\n",
    "    f_list = random.sample(range(len(feature_list)), size)\n",
    "    for i in f_list:\n",
    "        feature_batch_temp.append(feature_list[i])\n",
    "    for i in f_list:\n",
    "        label_batch_temp.append(label_list[i])\n",
    "    return feature_batch_temp,label_batch_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape,layer_name):\n",
    "    # Define a weight shape tensor of a shape shape\n",
    "    with tf.name_scope(layer_name + '_Weights'):\n",
    "        Weights = tf.Variable(tf.truncated_normal(shape, stddev=0.1),name='W')\n",
    "    tf.summary.histogram(layer_name + '_Weights', Weights)\n",
    "    return Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias_variable(shape,layer_name):\n",
    "    #defined a shape shape of the bias tensor\n",
    "    with tf.name_scope(layer_name + '_biases'):\n",
    "        biases = tf.Variable(tf.constant(0.1, shape=shape),name='b')\n",
    "    tf.summary.histogram(layer_name + '_biases', biases)\n",
    "    return biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W,layer_name):\n",
    "   #convolution calculation function\n",
    "   # stride [1, x steps, y steps, 1]\n",
    "   #padding:SAME/FULL/VALID (marginal processing)\n",
    "    with tf.name_scope(layer_name + '_h_conv2d'):\n",
    "        h_conv2d = tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    return h_conv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pool_2x2(x,layer_name):\n",
    "    #max pooling function\n",
    "    #ksize [1, x side length, y side length, 1] pooled window size\n",
    "    #stride [1, x steps, y steps, 1]\n",
    "    #padding:SAME/FULL/VALID (marginal processing)\n",
    "    with tf.name_scope(layer_name + '_h_pool'):\n",
    "        h_pool = tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "    return h_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    global feature\n",
    "    global label\n",
    "    global feature_full\n",
    "    global label_full\n",
    "    feature=[]\n",
    "    label=[]\n",
    "    feature_full=[]\n",
    "    label_full=[]\n",
    "    file_path ='kddcup/kddcup.data_10_percent_corrected_handled2.csv'\n",
    "    with (open(file_path,'r')) as data_from:\n",
    "        csv_reader=csv.reader(data_from)\n",
    "        for i in csv_reader:\n",
    "            # print (i)\n",
    "            label_list=[0]*23\n",
    "            feature.append(i[:36])\n",
    "            label_list[int(i[41])]=1\n",
    "            label.append(label_list)\n",
    "            # print label\n",
    "            # print feature\n",
    "        csv_reader = csv.reader(data_from)\n",
    "    file_path_full ='kddcup 2/kddcup.data.corrected_handled2.csv'\n",
    "    with (open(file_path_full,'r')) as data_from_full:\n",
    "        csv_reader_full=csv.reader(data_from_full)\n",
    "        for j in csv_reader_full:\n",
    "            # print i\n",
    "            label_list_full=[0]*23\n",
    "            feature_full.append(j[:36])\n",
    "            label_list_full[int(j[41])]=1\n",
    "            label_full.append(label_list_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__  == '__main__':\n",
    "    global feature\n",
    "    global label\n",
    "    global feature_full\n",
    "    global label_full\n",
    "    history_step = []\n",
    "    history_loss = []\n",
    "    history_train_accuracy = []\n",
    "    history_test_accuracy = []\n",
    "    #load data\n",
    "    load_data()\n",
    "    feature_test = feature\n",
    "    feature_train =feature_full\n",
    "    label_test = label\n",
    "    label_train = label_full\n",
    "    #Define the placeholder to enter\n",
    "    with tf.name_scope('inputs'):\n",
    "        xs = tf.placeholder(tf.float32, [None, 36],name='pic_data') # 6x6\n",
    "        ys = tf.placeholder(tf.float32, [None, 23],name='pic_label')\n",
    "        keep_prob = tf.placeholder(tf.float32,name='keep_prob')\n",
    "        x_image = tf.reshape(xs, [-1, 6, 6, 1])   \n",
    "\n",
    "    #The first convolution layer\n",
    "    with tf.name_scope('conv1_layer'):\n",
    "        W_conv1 = weight_variable([3,3,1,32],layer_name='conv1')  # convolution kernel 3x3, input thickness 1, output thickness 32\n",
    "        b_conv1 = bias_variable([32],layer_name='conv1')\n",
    "        h_conv1 = tf.nn.sigmoid(conv2d(x_image, W_conv1,layer_name='conv1') + b_conv1)    # Output size: 6x6x32\n",
    "        h_pool1 = max_pool_2x2(h_conv1,layer_name='conv1')                             # Output size: 3x3x32\n",
    "\n",
    "\n",
    "   #The first full connection layer\n",
    "   #with dropout\n",
    "    with tf.name_scope('fc1_layer'):\n",
    "        W_fc1 = weight_variable([3*3*32,1024],layer_name='fc1')\n",
    "        b_fc1 = bias_variable([1024],layer_name='fc1')\n",
    "        with tf.name_scope('reshape'):\n",
    "            h_pool2_flat = tf.reshape(h_pool1, [-1,3*3*32])\n",
    "        with tf.name_scope('sigmoid'):\n",
    "            h_fc1 = tf.nn.sigmoid(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "        with tf.name_scope('dropout'):\n",
    "            h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "            \n",
    "   #The second full connection layer\n",
    "    with tf.name_scope('fc2_layer'):\n",
    "        W_fc2 = weight_variable([1024, 23],layer_name='fc2')\n",
    "        b_fc2 = bias_variable([23],layer_name='fc2')\n",
    "        with tf.name_scope('softmax'):\n",
    "            prediction = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "\n",
    "\n",
    "    #Calculate loss/cost\n",
    "    with tf.name_scope('loss'):\n",
    "        cross_entropy = -tf.reduce_sum(ys * tf.log(prediction))       # loss\n",
    "    tf.summary.scalar('loss',cross_entropy)\n",
    "    #Calculate accuracy\n",
    "    with tf.name_scope('accuracy'):\n",
    "        correct_prediction = tf.equal(tf.argmax(prediction,1), tf.argmax(ys,1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar('accuracy', accuracy)\n",
    "    #Use the Adam optimizer to achieve the steepest gradient drop\n",
    "    with tf.name_scope('train'):\n",
    "        train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        #Initialize all tensors\n",
    "        sess.run(tf.initialize_all_variables())\n",
    "        #Draw the neural network structure\n",
    "        writer =tf.summary.FileWriter(\"multi_logs/\", sess.graph)\n",
    "        #Indicate the change in the tag value during training and evaluation\n",
    "        merged =  tf.summary.merge_all()\n",
    "        train_writer = tf.summary.FileWriter(\"multi_logs/train\", sess.graph)\n",
    "        test_writer = tf.summary.FileWriter(\"multi_logs/test\", sess.graph)\n",
    "\n",
    "        for step in range(501):\n",
    "            feature_train_batch, label_train_batch = next_batch(feature_train, label_train,1000)  #Random gradient descent training, each time you choose a batch of 1000\n",
    "            feature_test_batch, label_test_batch = next_batch(feature_test, label_test,1000)  \n",
    "            sess.run(train_step, feed_dict={xs: feature_train_batch, ys: label_train_batch, keep_prob: 0.5})\n",
    "            if step % 50 == 0:\n",
    "                train_writer.add_summary(sess.run(merged, feed_dict={xs: feature_train_batch, ys: label_train_batch, keep_prob: 1}), step)\n",
    "                test_writer.add_summary(sess.run(merged, feed_dict={xs: feature_test, ys: label_test, keep_prob: 1}), step)\n",
    "                history_step.append(step)\n",
    "                history_loss.append(sess.run(cross_entropy, feed_dict={xs: feature_train_batch, ys: label_train_batch, keep_prob: 1}))\n",
    "                history_test_accuracy.append(sess.run(accuracy, feed_dict={xs: feature_test, ys: label_test, keep_prob: 1}))\n",
    "                history_train_accuracy.append(sess.run(accuracy, feed_dict={xs: feature_train_batch, ys: label_train_batch, keep_prob: 1}))\n",
    "                print(step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# allow use of interactive plot controls, e.g., zoom\n",
    "get_ipython().run_line_magic('matplotlib', 'notebook')\n",
    "plt.figure()\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title('loss')\n",
    "plt.plot(history_step, history_loss)\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.title('train_accuracy')\n",
    "plt.plot(history_step, history_train_accuracy)\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.title('test_accuracy')\n",
    "plt.plot(history_step, history_test_accuracy)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
