{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io, os, sys, types\n",
    "from IPython import get_ipython\n",
    "from Utils import NotebookFinder\n",
    "import pandas as pd\n",
    "from Attack_RF import attack_RF\n",
    "from config_fileRF import config\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt  \n",
    "import numpy as np\n",
    "from Data_preprocessing import procedata\n",
    "import warnings\n",
    "from sklearn.decomposition import PCA\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = [81]#list(range(2,81,3))\n",
    "n_splits_k =  config[\"RF\"][\"n_splits_k\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pca():\n",
    "    datasets = pd.read_csv(\"data/attack_RF.csv\")\n",
    "    print (datasets.shape) \n",
    "    features = datasets.iloc[:, :-1]\n",
    "    labels = datasets.iloc[:, -1]\n",
    "    skf = StratifiedKFold(n_splits=n_splits_k,random_state = 2)\n",
    "    # The accracy_of_classes list holds the accuracy of each compromise\n",
    "    accracy_of_classes = []\n",
    "    # The precision_of_classes list holds the precision of each class in each compromise test set\n",
    "    precision_of_classes = []\n",
    "    # The recall_of_classes list holds the recall value of each class in each compromise test set\n",
    "    recall_of_classes = []\n",
    "    # The f1_of_classes list holds the f1 value of each class in each compromise test set\n",
    "    f1_of_classes = []\n",
    "    # flag is used to mark whether to output the training set and test set size，\n",
    "    # flag = 0 means no output, flag = 1 means output\n",
    "    flag = 0 \n",
    "    accuracy_mean = []\n",
    "    length_components = len(n_components)\n",
    "    components_flag = 0\n",
    "    precision_com =  np.zeros((14,length_components))\n",
    "    recall_com= np.zeros((14,length_components))\n",
    "    f1_com= np.zeros((14,length_components))\n",
    "    for n_com in n_components:\n",
    "        print(\"pca compressed dimension is：\",n_com)\n",
    "        #estimator = PCA(n_components=n_com)\n",
    "        for train_index, test_index in skf.split(features,labels):  \n",
    "            start = time.clock()\n",
    "            print(\"a\")\n",
    "            # The following is the training and test set segmentation process\n",
    "            features_train = features.iloc[train_index]\n",
    "            features_test =  features.iloc[test_index]\n",
    "            labels_train = labels.iloc[train_index]\n",
    "            labels_test =  labels.iloc[test_index]\n",
    "            features_train = features_train.values\n",
    "            labels_train = labels_train.values\n",
    "            features_test = features_test.values\n",
    "            labels_test = labels_test.values\n",
    "            labels_train = labels_train.reshape(len(labels_train))\n",
    "            labels_test = labels_test.reshape(len(labels_test))\n",
    "            if flag==0:\n",
    "                print(\"Number of examples in the train set:\",labels_train.shape)\n",
    "                print(\"Number of examples in the test set:\",labels_test.shape)\n",
    "                flag = 1\n",
    "            # attack_RF returns the accuracy of each test set and the precision, recall, and f1 values of each class \n",
    "#             features_train_pca = estimator.fit_transform(features_train)\n",
    "#             features_test_pca = estimator.transform(features_test)\n",
    "            accuracy,precision,recall,f1 = attack_RF(features_train,labels_train,features_test,labels_test)\n",
    "            precision_of_classes.append(precision)\n",
    "            recall_of_classes.append(recall)\n",
    "            f1_of_classes.append(f1)\n",
    "            accracy_of_classes.append(accuracy)\n",
    "        \n",
    "        end = time.clock()\n",
    "        print(\"Running time: %s seconds\"%(end - start))\n",
    "        # Find the average of all the precisions in all prediction sets in each compromise\n",
    "        precision_mean=np.mean(precision_of_classes,axis=0)\n",
    "        # Find the average of all the recall value in all prediction sets in each compromise\n",
    "        recall_mean = np.mean( recall_of_classes,axis=0)\n",
    "        # Find the average of all the f1 value in all prediction sets in each compromise\n",
    "        f1_mean = np.mean(f1_of_classes,axis=0)\n",
    "        acc_avg = np.mean(accracy_of_classes)\n",
    "        accuracy_mean.append(acc_avg)\n",
    "        for i in range(14):\n",
    "            precision_com[i][components_flag] = precision_mean[i]\n",
    "            recall_com[i][components_flag] = recall_mean[i]\n",
    "            f1_com[i][components_flag] = f1_mean[i]\n",
    "        print(\"accuracy_mean value is :\",acc_avg)\n",
    "        # Visualize the precision average, recall average, and f1 average of all classes in each compromise.\n",
    "        plt.figure()\n",
    "        x = range(1,len(precision)+1)\n",
    "        y1 = precision_mean\n",
    "        y2 = recall_mean\n",
    "        y3 = f1_mean\n",
    "        pre = plt.plot(x,y1,label = \"precision\")\n",
    "        rec = plt.plot(x,y2,label = \"recall\")\n",
    "        f1_ = plt.plot(x,y3,label = \"f1\") \n",
    "        plt.xlabel('labels of attack')\n",
    "        plt.legend(['precision','recall','f1'])\n",
    "        plt.show()\n",
    "        \n",
    "        plt.figure()\n",
    "        x = n_components[0:components_flag+1]\n",
    "        y1 = accuracy_mean\n",
    "        acc_mean = plt.plot(x,y1,label = \"accuracy_mean\")   \n",
    "        plt.xlabel('n_component')\n",
    "        plt.ylabel('accuracy mean')\n",
    "        plt.show()\n",
    "        \n",
    "        for i in range(14):   \n",
    "            plt.figure()\n",
    "            x = n_components[0:components_flag+1]\n",
    "            y1 = precision_com[i][0:components_flag+1]\n",
    "            y2 = recall_com[i][0:components_flag+1]\n",
    "            y3 = f1_com[i][0:components_flag+1]\n",
    "            pre = plt.plot(x,y1,label = \"precision of label{}\".format(i))\n",
    "            rec = plt.plot(x,y2,label = \"recall of label{}\".format(i))\n",
    "            f1_ = plt.plot(x,y3,label = \"f1 of label{}\".format(i)) \n",
    "            plt.xlabel('n_component')\n",
    "            plt.legend([\"precision of label{}\".format(i),\"recall of label{}\".format(i),\"f1 of label{}\".format(i)])\n",
    "            plt.show()\n",
    "        components_flag +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1252936, 82)\n",
      "pca compressed dimension is： 81\n",
      "a\n",
      "Number of examples in the train set: (1127635,)\n",
      "Number of examples in the test set: (125301,)\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    run_pca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}